/home/16amf8/anaconda3/envs/FER/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Setting up a new session...
Reading config file...
Initializing dataset...
dataset [FER2013Dataset] was created
The number of training samples = 28709
dataset [FER2013Dataset] was created
The number of validation samples = 3589
Initializing model...
model [FER2013model] was created
loading the model from /home/16amf8/ELEC872/FER_SSL/trials/base_affine/78_net_model.pth
loading the optimizer from /home/16amf8/ELEC872/FER_SSL/trials/base_affine/78_optimizer_0.pth
Networks initialized
FER2013_Feature_Expansion(
  (conv1): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (crelu): CReLU(
    (relu): ReLU()
  )
  (conv2): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (residual_1): ResidualUnit(
    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (_downsample): Sequential(
      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (residual_2): ResidualUnit(
    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (_downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (residual_3): ResidualUnit(
    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (_downsample): Sequential(
      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=1024, out_features=7, bias=True)
  (tanh): Tanh()
  (softmax): Softmax(dim=1)
)
[Network model] Total number of parameters : 2.980 M
Initializing visualization...
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 79/200, iter: 0/448] total: 0.818845 
[epoch: 79/200, iter: 25/448] total: 1.021189 
[epoch: 79/200, iter: 50/448] total: 0.974251 
[epoch: 79/200, iter: 75/448] total: 0.913868 
[epoch: 79/200, iter: 100/448] total: 0.983297 
[epoch: 79/200, iter: 125/448] total: 0.921732 
[epoch: 79/200, iter: 150/448] total: 1.025779 
[epoch: 79/200, iter: 175/448] total: 0.959546 
[epoch: 79/200, iter: 200/448] total: 1.017552 
[epoch: 79/200, iter: 225/448] total: 1.033091 
[epoch: 79/200, iter: 250/448] total: 1.074172 
[epoch: 79/200, iter: 275/448] total: 1.005612 
[epoch: 79/200, iter: 300/448] total: 1.210823 
[epoch: 79/200, iter: 325/448] total: 0.870326 
[epoch: 79/200, iter: 350/448] total: 0.895396 
[epoch: 79/200, iter: 375/448] total: 0.997299 
[epoch: 79/200, iter: 400/448] total: 1.003257 
[epoch: 79/200, iter: 425/448] total: 0.969620 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
/home/16amf8/ELEC872/FER_SSL/utils/radam.py:45: UserWarning: This overload of addcmul_ is deprecated:
	addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
	addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630836880/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
Validation accuracy: 0.585
Saving model at the end of epoch 79
End of epoch 79 / 200 	 Time Taken: 215.31306719779968 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 80/200, iter: 0/448] total: 0.880085 
[epoch: 80/200, iter: 25/448] total: 1.101836 
[epoch: 80/200, iter: 50/448] total: 1.040268 
[epoch: 80/200, iter: 75/448] total: 0.960637 
[epoch: 80/200, iter: 100/448] total: 0.906616 
[epoch: 80/200, iter: 125/448] total: 0.935297 
[epoch: 80/200, iter: 150/448] total: 0.964779 
[epoch: 80/200, iter: 175/448] total: 0.997940 
[epoch: 80/200, iter: 200/448] total: 1.008759 
[epoch: 80/200, iter: 225/448] total: 1.057024 
[epoch: 80/200, iter: 250/448] total: 1.073192 
[epoch: 80/200, iter: 275/448] total: 0.926147 
[epoch: 80/200, iter: 300/448] total: 1.126577 
[epoch: 80/200, iter: 325/448] total: 0.922395 
[epoch: 80/200, iter: 350/448] total: 0.931833 
[epoch: 80/200, iter: 375/448] total: 1.040766 
[epoch: 80/200, iter: 400/448] total: 0.916693 
[epoch: 80/200, iter: 425/448] total: 1.037526 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.585
Saving model at the end of epoch 80
End of epoch 80 / 200 	 Time Taken: 210.05837106704712 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 81/200, iter: 0/448] total: 0.895812 
[epoch: 81/200, iter: 25/448] total: 1.210999 
[epoch: 81/200, iter: 50/448] total: 0.988086 
[epoch: 81/200, iter: 75/448] total: 0.960968 
[epoch: 81/200, iter: 100/448] total: 0.962927 
[epoch: 81/200, iter: 125/448] total: 0.902662 
[epoch: 81/200, iter: 150/448] total: 0.990537 
[epoch: 81/200, iter: 175/448] total: 0.895684 
[epoch: 81/200, iter: 200/448] total: 1.053156 
[epoch: 81/200, iter: 225/448] total: 1.005042 
[epoch: 81/200, iter: 250/448] total: 1.060225 
[epoch: 81/200, iter: 275/448] total: 0.973415 
[epoch: 81/200, iter: 300/448] total: 1.114825 
[epoch: 81/200, iter: 325/448] total: 0.860100 
[epoch: 81/200, iter: 350/448] total: 0.920868 
[epoch: 81/200, iter: 375/448] total: 0.989734 
[epoch: 81/200, iter: 400/448] total: 0.973343 
[epoch: 81/200, iter: 425/448] total: 1.010799 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.581
Saving model at the end of epoch 81
End of epoch 81 / 200 	 Time Taken: 209.74311089515686 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 82/200, iter: 0/448] total: 0.882236 
[epoch: 82/200, iter: 25/448] total: 1.106474 
[epoch: 82/200, iter: 50/448] total: 0.969156 
[epoch: 82/200, iter: 75/448] total: 0.969509 
[epoch: 82/200, iter: 100/448] total: 0.861041 
[epoch: 82/200, iter: 125/448] total: 0.851072 
[epoch: 82/200, iter: 150/448] total: 1.023761 
[epoch: 82/200, iter: 175/448] total: 0.961657 
[epoch: 82/200, iter: 200/448] total: 1.035575 
[epoch: 82/200, iter: 225/448] total: 1.038029 
[epoch: 82/200, iter: 250/448] total: 1.022850 
[epoch: 82/200, iter: 275/448] total: 0.968673 
[epoch: 82/200, iter: 300/448] total: 1.112640 
[epoch: 82/200, iter: 325/448] total: 0.922833 
[epoch: 82/200, iter: 350/448] total: 0.897332 
[epoch: 82/200, iter: 375/448] total: 1.038470 
[epoch: 82/200, iter: 400/448] total: 1.044928 
[epoch: 82/200, iter: 425/448] total: 1.054784 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.588
Saving model at the end of epoch 82
End of epoch 82 / 200 	 Time Taken: 210.26052165031433 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 83/200, iter: 0/448] total: 0.902665 
[epoch: 83/200, iter: 25/448] total: 1.070362 
[epoch: 83/200, iter: 50/448] total: 1.020945 
[epoch: 83/200, iter: 75/448] total: 0.956841 
[epoch: 83/200, iter: 100/448] total: 0.940693 
[epoch: 83/200, iter: 125/448] total: 0.948624 
[epoch: 83/200, iter: 150/448] total: 0.888484 
[epoch: 83/200, iter: 175/448] total: 0.936480 
[epoch: 83/200, iter: 200/448] total: 0.984896 
[epoch: 83/200, iter: 225/448] total: 1.013769 
[epoch: 83/200, iter: 250/448] total: 1.009537 
[epoch: 83/200, iter: 275/448] total: 1.044700 
[epoch: 83/200, iter: 300/448] total: 1.114234 
[epoch: 83/200, iter: 325/448] total: 0.952268 
[epoch: 83/200, iter: 350/448] total: 0.911281 
[epoch: 83/200, iter: 375/448] total: 1.003703 
[epoch: 83/200, iter: 400/448] total: 0.998500 
[epoch: 83/200, iter: 425/448] total: 1.051205 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.597
Saving model at the end of epoch 83
End of epoch 83 / 200 	 Time Taken: 209.50606036186218 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 84/200, iter: 0/448] total: 0.860818 
[epoch: 84/200, iter: 25/448] total: 1.145857 
[epoch: 84/200, iter: 50/448] total: 1.014477 
[epoch: 84/200, iter: 75/448] total: 0.930909 
[epoch: 84/200, iter: 100/448] total: 0.930540 
[epoch: 84/200, iter: 125/448] total: 0.911923 
[epoch: 84/200, iter: 150/448] total: 0.985747 
[epoch: 84/200, iter: 175/448] total: 0.897099 
[epoch: 84/200, iter: 200/448] total: 0.989039 
[epoch: 84/200, iter: 225/448] total: 1.018005 
[epoch: 84/200, iter: 250/448] total: 1.049363 
[epoch: 84/200, iter: 275/448] total: 0.947159 
[epoch: 84/200, iter: 300/448] total: 1.071337 
[epoch: 84/200, iter: 325/448] total: 0.907847 
[epoch: 84/200, iter: 350/448] total: 0.948574 
[epoch: 84/200, iter: 375/448] total: 0.993413 
[epoch: 84/200, iter: 400/448] total: 0.963711 
[epoch: 84/200, iter: 425/448] total: 1.112131 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.605
Saving model at the end of epoch 84
End of epoch 84 / 200 	 Time Taken: 209.8708257675171 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 85/200, iter: 0/448] total: 0.855434 
[epoch: 85/200, iter: 25/448] total: 1.108115 
[epoch: 85/200, iter: 50/448] total: 1.030286 
[epoch: 85/200, iter: 75/448] total: 0.935438 
[epoch: 85/200, iter: 100/448] total: 0.994655 
[epoch: 85/200, iter: 125/448] total: 0.890777 
[epoch: 85/200, iter: 150/448] total: 1.006724 
[epoch: 85/200, iter: 175/448] total: 0.926848 
[epoch: 85/200, iter: 200/448] total: 0.986739 
[epoch: 85/200, iter: 225/448] total: 1.090490 
[epoch: 85/200, iter: 250/448] total: 1.009119 
[epoch: 85/200, iter: 275/448] total: 0.958444 
[epoch: 85/200, iter: 300/448] total: 1.063198 
[epoch: 85/200, iter: 325/448] total: 0.962510 
[epoch: 85/200, iter: 350/448] total: 0.942874 
[epoch: 85/200, iter: 375/448] total: 1.082521 
[epoch: 85/200, iter: 400/448] total: 0.934045 
[epoch: 85/200, iter: 425/448] total: 1.004686 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.592
Saving model at the end of epoch 85
End of epoch 85 / 200 	 Time Taken: 210.99057936668396 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 86/200, iter: 0/448] total: 0.893821 
[epoch: 86/200, iter: 25/448] total: 1.050102 
[epoch: 86/200, iter: 50/448] total: 1.068447 
[epoch: 86/200, iter: 75/448] total: 0.932781 
[epoch: 86/200, iter: 100/448] total: 0.892548 
[epoch: 86/200, iter: 125/448] total: 0.927875 
[epoch: 86/200, iter: 150/448] total: 0.983272 
[epoch: 86/200, iter: 175/448] total: 0.927018 
[epoch: 86/200, iter: 200/448] total: 1.007814 
[epoch: 86/200, iter: 225/448] total: 1.028988 
[epoch: 86/200, iter: 250/448] total: 1.053092 
[epoch: 86/200, iter: 275/448] total: 0.977988 
[epoch: 86/200, iter: 300/448] total: 1.103523 
[epoch: 86/200, iter: 325/448] total: 0.855181 
[epoch: 86/200, iter: 350/448] total: 0.930371 
[epoch: 86/200, iter: 375/448] total: 0.983109 
[epoch: 86/200, iter: 400/448] total: 0.969368 
[epoch: 86/200, iter: 425/448] total: 1.069069 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.590
Saving model at the end of epoch 86
End of epoch 86 / 200 	 Time Taken: 210.55057096481323 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 87/200, iter: 0/448] total: 0.848676 
[epoch: 87/200, iter: 25/448] total: 1.105249 
[epoch: 87/200, iter: 50/448] total: 0.999721 
[epoch: 87/200, iter: 75/448] total: 0.896626 
[epoch: 87/200, iter: 100/448] total: 0.937677 
[epoch: 87/200, iter: 125/448] total: 0.930888 
[epoch: 87/200, iter: 150/448] total: 0.945753 
[epoch: 87/200, iter: 175/448] total: 0.976610 
[epoch: 87/200, iter: 200/448] total: 0.935824 
[epoch: 87/200, iter: 225/448] total: 1.121592 
[epoch: 87/200, iter: 250/448] total: 1.003373 
[epoch: 87/200, iter: 275/448] total: 0.984336 
[epoch: 87/200, iter: 300/448] total: 1.062891 
[epoch: 87/200, iter: 325/448] total: 0.929635 
[epoch: 87/200, iter: 350/448] total: 0.868441 
[epoch: 87/200, iter: 375/448] total: 0.976393 
[epoch: 87/200, iter: 400/448] total: 0.974921 
[epoch: 87/200, iter: 425/448] total: 1.004450 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.614
Saving model at the end of epoch 87
End of epoch 87 / 200 	 Time Taken: 209.91434574127197 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 88/200, iter: 0/448] total: 0.892790 
[epoch: 88/200, iter: 25/448] total: 1.027583 
[epoch: 88/200, iter: 50/448] total: 1.105055 
[epoch: 88/200, iter: 75/448] total: 0.971781 
[epoch: 88/200, iter: 100/448] total: 0.972967 
[epoch: 88/200, iter: 125/448] total: 0.878675 
[epoch: 88/200, iter: 150/448] total: 0.956543 
[epoch: 88/200, iter: 175/448] total: 0.958616 
[epoch: 88/200, iter: 200/448] total: 1.006646 
[epoch: 88/200, iter: 225/448] total: 0.938158 
[epoch: 88/200, iter: 250/448] total: 1.056632 
[epoch: 88/200, iter: 275/448] total: 1.016215 
[epoch: 88/200, iter: 300/448] total: 1.133833 
[epoch: 88/200, iter: 325/448] total: 0.932002 
[epoch: 88/200, iter: 350/448] total: 0.951205 
[epoch: 88/200, iter: 375/448] total: 1.000832 
[epoch: 88/200, iter: 400/448] total: 0.997132 
[epoch: 88/200, iter: 425/448] total: 1.024479 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.604
Saving model at the end of epoch 88
End of epoch 88 / 200 	 Time Taken: 209.84928727149963 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 89/200, iter: 0/448] total: 0.850855 
[epoch: 89/200, iter: 25/448] total: 1.093057 
[epoch: 89/200, iter: 50/448] total: 1.027732 
[epoch: 89/200, iter: 75/448] total: 0.949345 
[epoch: 89/200, iter: 100/448] total: 0.918386 
[epoch: 89/200, iter: 125/448] total: 0.928117 
[epoch: 89/200, iter: 150/448] total: 0.952597 
[epoch: 89/200, iter: 175/448] total: 0.960022 
[epoch: 89/200, iter: 200/448] total: 0.998480 
[epoch: 89/200, iter: 225/448] total: 1.009788 
[epoch: 89/200, iter: 250/448] total: 1.026310 
[epoch: 89/200, iter: 275/448] total: 1.003271 
[epoch: 89/200, iter: 300/448] total: 1.079510 
[epoch: 89/200, iter: 325/448] total: 0.839152 
[epoch: 89/200, iter: 350/448] total: 0.856093 
[epoch: 89/200, iter: 375/448] total: 1.013896 
[epoch: 89/200, iter: 400/448] total: 0.975575 
[epoch: 89/200, iter: 425/448] total: 1.070425 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.591
Saving model at the end of epoch 89
End of epoch 89 / 200 	 Time Taken: 209.804053068161 sec
learning rate = 0.0001000
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 90/200, iter: 0/448] total: 0.864967 
[epoch: 90/200, iter: 25/448] total: 1.078833 
[epoch: 90/200, iter: 50/448] total: 1.009197 
[epoch: 90/200, iter: 75/448] total: 0.889575 
[epoch: 90/200, iter: 100/448] total: 0.918645 
[epoch: 90/200, iter: 125/448] total: 0.932349 
[epoch: 90/200, iter: 150/448] total: 0.924235 
[epoch: 90/200, iter: 175/448] total: 0.948660 
[epoch: 90/200, iter: 200/448] total: 1.000774 
[epoch: 90/200, iter: 225/448] total: 1.000221 
[epoch: 90/200, iter: 250/448] total: 0.972773 
[epoch: 90/200, iter: 275/448] total: 0.950410 
[epoch: 90/200, iter: 300/448] total: 1.119164 
[epoch: 90/200, iter: 325/448] total: 0.939567 
[epoch: 90/200, iter: 350/448] total: 0.852238 
[epoch: 90/200, iter: 375/448] total: 0.962336 
[epoch: 90/200, iter: 400/448] total: 0.968382 
[epoch: 90/200, iter: 425/448] total: 0.976560 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.597
Saving model at the end of epoch 90
End of epoch 90 / 200 	 Time Taken: 210.96312069892883 sec
learning rate = 0.0000300
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 91/200, iter: 0/448] total: 0.865064 
[epoch: 91/200, iter: 25/448] total: 1.170312 
[epoch: 91/200, iter: 50/448] total: 0.969790 
[epoch: 91/200, iter: 75/448] total: 0.867579 
[epoch: 91/200, iter: 100/448] total: 0.849892 
[epoch: 91/200, iter: 125/448] total: 0.831949 
[epoch: 91/200, iter: 150/448] total: 0.906901 
[epoch: 91/200, iter: 175/448] total: 0.916541 
[epoch: 91/200, iter: 200/448] total: 0.895475 
[epoch: 91/200, iter: 225/448] total: 0.976662 
[epoch: 91/200, iter: 250/448] total: 0.919032 
[epoch: 91/200, iter: 275/448] total: 0.861574 
[epoch: 91/200, iter: 300/448] total: 1.084567 
[epoch: 91/200, iter: 325/448] total: 0.835644 
[epoch: 91/200, iter: 350/448] total: 0.899569 
[epoch: 91/200, iter: 375/448] total: 0.977659 
[epoch: 91/200, iter: 400/448] total: 0.911322 
[epoch: 91/200, iter: 425/448] total: 0.972589 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.621
Saving model at the end of epoch 91
End of epoch 91 / 200 	 Time Taken: 211.07505774497986 sec
learning rate = 0.0000300
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 92/200, iter: 0/448] total: 0.802013 
[epoch: 92/200, iter: 25/448] total: 1.049457 
[epoch: 92/200, iter: 50/448] total: 0.885802 
[epoch: 92/200, iter: 75/448] total: 0.863020 
[epoch: 92/200, iter: 100/448] total: 0.897590 
[epoch: 92/200, iter: 125/448] total: 0.816976 
[epoch: 92/200, iter: 150/448] total: 0.905631 
[epoch: 92/200, iter: 175/448] total: 0.875480 
[epoch: 92/200, iter: 200/448] total: 0.859756 
[epoch: 92/200, iter: 225/448] total: 0.937611 
[epoch: 92/200, iter: 250/448] total: 0.941018 
[epoch: 92/200, iter: 275/448] total: 0.855958 
[epoch: 92/200, iter: 300/448] total: 1.034973 
[epoch: 92/200, iter: 325/448] total: 0.828188 
[epoch: 92/200, iter: 350/448] total: 0.843942 
[epoch: 92/200, iter: 375/448] total: 0.985743 
[epoch: 92/200, iter: 400/448] total: 0.941712 
[epoch: 92/200, iter: 425/448] total: 0.904761 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.619
Saving model at the end of epoch 92
End of epoch 92 / 200 	 Time Taken: 212.14692163467407 sec
learning rate = 0.0000300
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 93/200, iter: 0/448] total: 0.822112 
[epoch: 93/200, iter: 25/448] total: 1.025150 
[epoch: 93/200, iter: 50/448] total: 0.905456 
[epoch: 93/200, iter: 75/448] total: 0.887640 
[epoch: 93/200, iter: 100/448] total: 0.862958 
[epoch: 93/200, iter: 125/448] total: 0.804344 
[epoch: 93/200, iter: 150/448] total: 0.881762 
[epoch: 93/200, iter: 175/448] total: 0.898138 
[epoch: 93/200, iter: 200/448] total: 0.910523 
[epoch: 93/200, iter: 225/448] total: 0.903490 
[epoch: 93/200, iter: 250/448] total: 0.921164 
[epoch: 93/200, iter: 275/448] total: 0.853138 
[epoch: 93/200, iter: 300/448] total: 0.995748 
[epoch: 93/200, iter: 325/448] total: 0.889461 
[epoch: 93/200, iter: 350/448] total: 0.825800 
[epoch: 93/200, iter: 375/448] total: 0.914859 
[epoch: 93/200, iter: 400/448] total: 0.880277 
[epoch: 93/200, iter: 425/448] total: 0.873315 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.621
Saving model at the end of epoch 93
End of epoch 93 / 200 	 Time Taken: 212.3701810836792 sec
learning rate = 0.0000300
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 94/200, iter: 0/448] total: 0.797614 
[epoch: 94/200, iter: 25/448] total: 1.001365 
[epoch: 94/200, iter: 50/448] total: 0.937495 
[epoch: 94/200, iter: 75/448] total: 0.888241 
[epoch: 94/200, iter: 100/448] total: 0.854209 
[epoch: 94/200, iter: 125/448] total: 0.815001 
[epoch: 94/200, iter: 150/448] total: 0.849349 
[epoch: 94/200, iter: 175/448] total: 0.861084 
[epoch: 94/200, iter: 200/448] total: 0.888000 
[epoch: 94/200, iter: 225/448] total: 0.918044 
[epoch: 94/200, iter: 250/448] total: 0.946152 
[epoch: 94/200, iter: 275/448] total: 0.952735 
[epoch: 94/200, iter: 300/448] total: 1.024614 
[epoch: 94/200, iter: 325/448] total: 0.856251 
[epoch: 94/200, iter: 350/448] total: 0.835230 
[epoch: 94/200, iter: 375/448] total: 0.952853 
[epoch: 94/200, iter: 400/448] total: 0.894566 
[epoch: 94/200, iter: 425/448] total: 0.900704 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
Validation accuracy: 0.623
Saving model at the end of epoch 94
End of epoch 94 / 200 	 Time Taken: 211.22575426101685 sec
learning rate = 0.0000300
[-1, -1, -1, -1, -1, -1, -1]
[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
[epoch: 95/200, iter: 0/448] total: 0.799622 
[epoch: 95/200, iter: 25/448] total: 1.009500 
[epoch: 95/200, iter: 50/448] total: 0.927609 
[epoch: 95/200, iter: 75/448] total: 0.903812 
[epoch: 95/200, iter: 100/448] total: 0.845158 
[epoch: 95/200, iter: 125/448] total: 0.831268 
[epoch: 95/200, iter: 150/448] total: 0.860720 
[epoch: 95/200, iter: 175/448] total: 0.885055 
[epoch: 95/200, iter: 200/448] total: 0.894233 
[epoch: 95/200, iter: 225/448] total: 0.952320 
[epoch: 95/200, iter: 250/448] total: 0.914041 
[epoch: 95/200, iter: 275/448] total: 0.888383 
[epoch: 95/200, iter: 300/448] total: 1.008198 
[epoch: 95/200, iter: 325/448] total: 0.842753 
[epoch: 95/200, iter: 350/448] total: 0.799288 
[epoch: 95/200, iter: 375/448] total: 0.934034 
[epoch: 95/200, iter: 400/448] total: 0.870046 
[epoch: 95/200, iter: 425/448] total: 0.948763 
Max Confidence from Epoch [-1, -1, -1, -1, -1, -1, -1]
